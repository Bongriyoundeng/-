import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader, random_split
from tqdm import tqdm
import copy

# 데이터 전처리
transform = transforms.Compose([
    transforms.Resize((120, 280)),
    transforms.ToTensor(),
    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))
])

# 전체 데이터셋 로드
full_data = datasets.ImageFolder(r'주소', transform=transform)

# 데이터셋 분할
train_size = int(0.7 * len(full_data))
val_size = int(0.2 * len(full_data))
test_size = len(full_data) - train_size - val_size

train_data, val_data, test_data = random_split(full_data, [train_size, val_size, test_size])

train_loader = DataLoader(train_data, batch_size=32, shuffle=True)
val_loader = DataLoader(val_data, batch_size=32, shuffle=False)
test_loader = DataLoader(test_data, batch_size=32, shuffle=False)

# 모델 정의 함수
def initialize_model(model_name, num_classes, feature_extract=False):
    if model_name == "resnet":
        model = models.resnet18(pretrained=True)
        set_parameter_requires_grad(model, feature_extract)
        num_ftrs = model.fc.in_features
        model.fc = nn.Linear(num_ftrs, num_classes)
    elif model_name == "efficientnet":
        model = models.efficientnet_b1(pretrained=True)
        set_parameter_requires_grad(model, feature_extract)
        num_ftrs = model.classifier[1].in_features
        model.classifier[1] = nn.Linear(num_ftrs, num_classes)
    elif model_name == "resnext":
        model = models.resnext50_32x4d(pretrained=True)
        set_parameter_requires_grad(model, feature_extract)
        num_ftrs = model.fc.in_features
        model.fc = nn.Linear(num_ftrs, num_classes)
    return model

def set_parameter_requires_grad(model, feature_extracting):
    if feature_extracting:
        for param in model.parameters():
            param.requires_grad = False

# 훈련 함수 정의
def train(model, train_loader, criterion, optimizer, device):
    model.train()
    running_loss = 0.0
    corr = 0 
    for inputs, labels in tqdm(train_loader, desc='Training', unit='batch'):
        inputs, labels = inputs.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        _, pred = outputs.max(dim=1) 
        corr += pred.eq(labels).sum().item()
        running_loss += loss.item() * inputs.size(0)
    acc = corr / len(train_loader.dataset)
    epoch_loss = running_loss / len(train_loader.dataset)
    return epoch_loss, acc

# 검증 함수 정의
def validate(model, val_loader, criterion, device):
    model.eval()
    corr = 0
    val_loss = 0.0
    with torch.no_grad():
        for inputs, labels in tqdm(val_loader, desc='Validation', unit='batch'):
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            _, pred = outputs.max(dim=1)   
            corr += torch.sum(pred.eq(labels)).item()
            loss = criterion(outputs, labels)
            val_loss += loss.item() * inputs.size(0)
    acc = corr / len(val_loader.dataset)
    val_loss /= len(val_loader.dataset)
    return val_loss, acc

# 디바이스 설정 (GPU 사용 가능 여부 확인)
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# 모델 초기화
model_names = ["efficientnet"]  # "efficientnet" 또는 "resnext"로 변경 가능"resnet",,"resnext"
num_classes = len(full_data.class_to_idx)  # 분류할 클래스 수

model_name = "efficientnet"

model = initialize_model(model_name, num_classes, feature_extract=True)

# 모델을 디바이스로 이동
model = model.to(device)

# 손실 함수와 옵티마이저 정의
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# 에포크 수 설정
num_epochs = 10


for model_name in model_names:
    num_classes = len(full_data.class_to_idx)  # 분류할 클래스 수
    model = initialize_model(model_name, num_classes, feature_extract=True)
    
    # 모델을 디바이스로 이동
    model = model.to(device)
    
    # 손실 함수와 옵티마이저 정의
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    # 에포크 수 설정
    num_epochs = 100
    
    # 모델 훈련 및 검증
    best_model_wts = copy.deepcopy(model.state_dict())
    torch.save(model.state_dict(), f'{model_name}.pth')
    best_loss = float('inf')
    
    
    for epoch in range(num_epochs):
        train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)
        val_loss, val_acc = validate(model, val_loader, criterion, device)
    
        if val_loss < best_loss:
            print(f'[INFO] val_loss has been improved from {best_loss:.5f} to {val_loss:.5f}. Saving Model!')
            best_loss = val_loss
            torch.save(model.state_dict(), f'{model_name}.pth')
            
        print(f'epoch {epoch+1:02d}, loss: {train_loss:.5f}, acc: {train_acc:.5f}, val_loss: {val_loss:.5f}, val_accuracy: {val_acc:.5f}')

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
for model_name in model_names:
    num_classes = len(full_data.class_to_idx)  # 분류할 클래스 수
    model = initialize_model(model_name, num_classes, feature_extract=True)

    
    # 모델 로드
    model.load_state_dict(torch.load(f'{model_name}.pth', map_location=device))
    model = model.to(device)
    # 손실 함수와 옵티마이저 정의
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    # 평가 함수 정의
    def model_evaluate(model, data_loader, criterion, device):
        model.eval()
        total_loss = 0
        correct = 0
        total = 0
        all_labels = []
        all_preds = []
        with torch.no_grad():
            for inputs, labels in data_loader:
                inputs, labels = inputs.to(device), labels.to(device)
                outputs = model(inputs)
                loss = criterion(outputs, labels)
                total_loss += loss.item()
                _, predicted = torch.max(outputs, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
                all_labels.extend(labels.cpu().numpy())
                all_preds.extend(predicted.cpu().numpy())
        avg_loss = total_loss / len(data_loader)
        accuracy = correct / total
        return avg_loss, accuracy, all_labels, all_preds
    
    # 평가 진행
    final_loss, final_acc, all_labels, all_preds = model_evaluate(model, test_loader, criterion, device)
    
    # 혼동 행렬 계산 및 시각화
    cm = confusion_matrix(all_labels, all_preds)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm)
    disp.plot(cmap=plt.cm.Blues)
    plt.show()
    print(model_name)
    
    
    
    # 결과 출력
    print(f'evaluation loss: {final_loss:.5f}, evaluation accuracy: {final_acc:.5f}')



#모델을 활용한 Sample 확보

import torch.nn.functional as F
import glob
dataset = mkDataset(r'주소')


dataloader = DataLoader(dataset, batch_size = 64, num_workers=0, shuffle = False)

model_name = model_names[0]

num_classes = len(full_data.class_to_idx)  # 분류할 클래스 수
model = initialize_model(model_name, num_classes, feature_extract=True)

# 모델 로드
model.load_state_dict(torch.load(f'{model_name}.pth', map_location=device))

model.eval()
preds = []
pred_ratio = []
p_idx = []
img_path = []
model.to(device)

for img, idx, img_name in tqdm(dataloader): #tqdm()
    img = img.to(device)
    outputs = model(img)
    predicted = torch.argmax(outputs, dim =1).detach().cpu().tolist()
    predicted_ratio = F.softmax(outputs, dim =1).detach().cpu().tolist()
    idx = idx.detach().cpu().tolist()
    img_path.extend(img_name)
    p_idx.extend(idx)
    pred_ratio.extend(predicted_ratio)
    preds.extend(predicted)

img_names = {j:i for (i,j) in full_data.class_to_idx.items()}
img_names

import numpy as np
preds = [img_names[p] for p in preds]
pred_ratio = [np.array(p).max() for p in pred_ratio]

r_path = r'주소'
import shutil
for adr, prd, prr in zip(img_path, preds, pred_ratio):
    if (os.path.basename(os.path.dirname(adr)) == prd) & (prr < 0.9):
        t_path = os.path.join(r_path,'low_record'+prd)
        if os.path.isdir(t_path):
            shutil.move(adr, t_path)
        else:
            os.makedirs(t_path)
            shutil.move(adr, t_path)
    elif (os.path.basename(os.path.dirname(adr)) != prd) :
        t_path = os.path.join(r_path,'pred'+prd)
        if os.path.isdir(t_path):
            shutil.move(adr, t_path)
        else:
            os.makedirs(t_path)
            shutil.move(adr, t_path) 
    else : 
        pass
