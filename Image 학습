import matplotlib.pyplot as plt
import torchvision
import torch
import torch.nn as nn
import torchvision.transforms as T
from torchvision.transforms import ToTensor, Compose
from torchvision import transforms
from torch.utils.data import DataLoader, Dataset
from torchvision.datasets import ImageFolder
import os
from pathlib import Path
import pandas as pd
from PIL import Image
import glob
import numpy as np
import pandas as pd

spath = input('학습 image 위치:')
spath = spath.replace('\\','/')
dir_ = Path(spath)
filepaths = list(dir_.glob(r'*/*.jpg'))
def proc_img(filepath):
    """
   		이미지데이터의 경로와 label데이터로 데이터프레임 만들기 
    """

    labels = [str(filepath[i]).split("\\")[-2] for i in range(len(filepaths))]

    filepath = pd.Series(filepath, name='Filepath').astype(str)
    labels = pd.Series(labels, name='Label')

    # 경로와 라벨 concatenate
    df = pd.concat([filepath, labels], axis=1)

    # index 재설정
    df = df.sample(frac=1,random_state=0).reset_index(drop = True)
    
    return df

df = proc_img(filepaths)
df.head(5)

df['Label'].value_counts()

img_T = T.Compose([
    T.CenterCrop((120,280)),
    # T.Resize((120,120)),
    #T.RandomRotation(degrees=(-90,90)),
    T.RandomVerticalFlip(p=0.5),
    T.RandomHorizontalFlip(p=0.5),
    T.ColorJitter(brightness = 0.5),
    T.ColorJitter(saturation = 0.5),
    #
    T.ToTensor(),
    # T.Normalize((0.5), (0.5))# T.Normalize([0.5],[0.5])
])

def make_weights(labels, nclasses):
    labels = np.array(labels)
    weight_list = []
    
    for cls in range(nclasses):
        idx = np.where(labels == cls)[0]
        count = len(idx)
        weight = 1/count
        weights = [weight]*count
        weight_list += weights
        
    return weight_list

image_folder = ImageFolder(root=dir_,transform=img_T)

img_names=image_folder.classes
print(img_names)
len(img_names)

from torch.utils.data import Subset

batch_size = 2
validation_split = 0.2
shuffle_dataset = True
random_seed =42

dataset_size = len(image_folder)
indices =list(range(dataset_size))
split = int(np.floor(validation_split*dataset_size))

if shuffle_dataset:
    np.random.seed(random_seed)
    np.random.shuffle(indices)
    
train_indices, val_indices, test_indices = indices[split*2:], indices[:split], indices[split:split*2]
train_sampler = Subset(image_folder,train_indices)
valid_sampler = Subset(image_folder,val_indices)
test_sampler = Subset(image_folder,test_indices)

#train_size=int(0.6*len(image_folder))
#test_size=int(0.2*len(image_folder))
#f_test_size =len(image_folder)-train_size-test_size

#train_dataset, test_dataset = torch.utils.data.random_split(image_folder,[train_size,test_size])

weights = make_weights(Subset(image_folder.targets,train_indices), len(img_names))
weights = torch.DoubleTensor(weights)

sampler = torch.utils.data.sampler.WeightedRandomSampler(weights,len(weights))

train_loader = DataLoader(train_sampler,batch_size=126,num_workers=8,sampler = sampler)

valid_loader = DataLoader(valid_sampler,batch_size=126,shuffle=False,num_workers=4)

test_loader = DataLoader(test_sampler,batch_size=126,shuffle=False,num_workers=4)

images, labels = next(iter(train_loader))

images.shape, labels.shape

labels_map = {v:k for k, v in image_folder.class_to_idx.items()}

figure = plt.figure(figsize=(12, 16))
cols, rows = 8, 10



for i in range(1, cols * rows + 1):
    sample_idx = torch.randint(len(images), size=(1,)).item()
    img, label = images[sample_idx], labels[sample_idx].item()
    figure.add_subplot(rows, cols, i)
    plt.title(labels_map[label])
    plt.axis("off")
    plt.imshow(torch.permute(img, (1, 2, 0)))
plt.show()

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(device)


from torchvision import models # pretrained 모델을 가져오기 위한 import
#resnet18 = 'C:/Users/IPC/Desktop/파이썬/resnet18-f37072fd.pth'

model = models.resnet18(weights=True)

# 가중치를 Freeze 하여 학습시 업데이트가 일어나지 않도록 설정합니다.
for param in model.parameters():
    param.requires_grad = False  # 가중치 Freeze

from torchvision import models # pretrained 모델을 가져오기 위한 import

import torch.nn as nn

model = models.resnet18(pretrained=True)

num_ftrs = model.fc.in_features

# model = nn.DataParallel(model)

model.fc = nn.Linear(num_ftrs, len(image_folder.classes))

model.to(device)

model

import torch.optim as optim

# 옵티마이저를 정의합니다. 옵티마이저에는 model.parameters()를 지정해야 합니다.
optimizer = optim.Adadelta(model.parameters(), lr=0.001) Adam

# 손실함수(loss function)을 지정합니다. Multi-Class Classification 이기 때문에 CrossEntropy 손실을 지정하였습니다.
loss_fn = nn.CrossEntropyLoss()

from tqdm import tqdm  # Progress Bar 출력

def model_train(model, data_loader, loss_fn, optimizer, device):
    model.train()
    running_loss = 0
    corr = 0
    prograss_bar = tqdm(data_loader)
    
    for img, lbl in prograss_bar:
        img, lbl = img.to(device), lbl.to(device) 
        optimizer.zero_grad()
        output = model(img)        
        loss = loss_fn(output, lbl)        
        loss.backward()        
        optimizer.step()        
        _, pred = output.max(dim=1)        
        corr += pred.eq(lbl).sum().item()        
        running_loss += loss.item() * img.size(0)        
    acc = corr / len(data_loader.dataset)    
    return running_loss / len(data_loader.dataset), acc

def model_evaluate(model, data_loader, loss_fn, device):
    model.eval()
    with torch.no_grad():
        corr = 0
        running_loss = 0  
        for img, lbl in data_loader:            
            img, lbl = img.to(device), lbl.to(device)          
            output = model(img)           
            _, pred = output.max(dim=1)            
            corr += torch.sum(pred.eq(lbl)).item()           
            running_loss += loss_fn(output, lbl).item() * img.size(0)      
        acc = corr / len(data_loader.dataset)
      
        return running_loss / len(data_loader.dataset), acc

num_epochs = 300
model_name = input('가중치_Name:')
#'resnet18-pretrained_AAI_Mid'
min_loss = np.inf

%%time
# num_epochs = 41
for epoch in range(num_epochs):
    train_loss, train_acc = model_train(model, train_loader, loss_fn, optimizer, device)

    val_loss, val_acc = model_evaluate(model, valid_loader, loss_fn, device)   
    
    if val_loss < min_loss:
        print(f'[INFO] val_loss has been improved from {min_loss:.5f} to {val_loss:.5f}. Saving Model!')
        min_loss = val_loss
        torch.save(model.state_dict(), f'{model_name}.pth')
    
    print(f'epoch {epoch+1:02d}, loss: {train_loss:.5f}, acc: {train_acc:.5f}, val_loss: {val_loss:.5f}, val_accuracy: {val_acc:.5f}')


from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# 모델 로드
model.load_state_dict(torch.load(f'{model_name}.pth', map_location=device))

# 평가 함수 정의
def model_evaluate(model, data_loader, loss_fn, device):
    model.eval()
    total_loss = 0
    correct = 0
    total = 0
    all_labels = []
    all_preds = []
    with torch.no_grad():
        for images, labels in data_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = loss_fn(outputs, labels)
            total_loss += loss.item()
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
            all_labels.extend(labels.cpu().numpy())
            all_preds.extend(predicted.cpu().numpy())
    avg_loss = total_loss / len(data_loader)
    accuracy = correct / total
    return avg_loss, accuracy, all_labels, all_preds

# 평가 진행
final_loss, final_acc, all_labels, all_preds = model_evaluate(model, test_loader, loss_fn, device)

# 혼동 행렬 계산 및 시각화
cm = confusion_matrix(all_labels, all_preds)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap=plt.cm.Blues)
plt.show()
print(img_names)
# 결과 출력
print(f'evaluation loss: {final_loss:.5f}, evaluation accuracy: {final_acc:.5f}')
