import matplotlib.pyplot as plt
import torchvision
import torch
import torch.nn as nn
import torchvision.transforms as T
from torchvision.transforms import ToTensor, Compose
from torchvision import transforms, models  
from torch.utils.data import DataLoader, Dataset, Subset
from torchvision.datasets import ImageFolder
import os
from pathlib import Path
import pandas as pd
from PIL import Image
import glob
import numpy as np
import random
import torch.optim as optim
from tqdm import tqdm

# Custom dataset to include image and meta information
class CustomDataset(Dataset):
    def __init__(self, image_paths, transform=None):
        self.image_paths = image_paths
        self.transform = transform
        self.labels = [str(path).split("\\")[-2] for path in image_paths]
        self.classes = list(set(self.labels))
        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}
        self.label_indices = [self.class_to_idx[label] for label in self.labels]

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        image_path = self.image_paths[idx]
        image = Image.open(image_path).convert('RGB')
        if self.transform:
            image = self.transform(image)        
        filename = os.path.basename(image_path)        
        meta_size = int(filename.split('.')[-2])
        meta_peak = int(filename.split('.')[-1])        
        meta_data = torch.tensor([meta_size, meta_peak], dtype=torch.float32)        
        label = str(image_path).split("\\")[-2]        
        return image, meta_data, label

class ResNetWithMeta(nn.Module):
    def __init__(self, num_meta_features, num_classes):
        super(ResNetWithMeta, self).__init__()
        self.resnet = models.resnet18(pretrained=True)
        self.resnet.fc = nn.Identity()  # Remove the final fully connected layer
        self.meta_fc = nn.Linear(num_meta_features, 128)
        self.fc1 = nn.Linear(512 + 128, 256)
        #self.fc1 = nn.Linear(2048 + 128, 256) #REesNET50's output
        self.fc2 = nn.Linear(256, num_classes)

    def forward(self, x, meta):
        x = self.resnet(x)
        meta = torch.relu(self.meta_fc(meta))
        x = torch.cat((x, meta), dim=1)
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)
        return x

if __name__ == "__main__":
    dir_ = Path('이미지주소')
    filepaths = list(dir_.glob(r'*/*.jpg'))

    img_T = T.Compose([
        T.Resize((120,280)),
        T.RandomAdjustSharpness(sharpness_factor=2),
        T.GaussianBlur(kernel_size=(5,9), sigma=(0.1,5)),
        T.RandomVerticalFlip(p=0.5),
        T.RandomHorizontalFlip(p=0.5),
        T.ColorJitter(brightness=0.5),
        T.ColorJitter(saturation=0.5),
        T.ToTensor()
    ])

    dataset = CustomDataset(filepaths, transform=img_T)
    batch_size = 2
    validation_split = 0.2
    shuffle_dataset = True
    random_seed = 44
    dataset_size = len(dataset)
    indices = list(range(dataset_size))
    split = int(np.floor(validation_split * dataset_size))
    if shuffle_dataset:
        np.random.seed(random_seed)
        np.random.shuffle(indices)
    train_indices, val_indices, test_indices = indices[split*2:], indices[:split], indices[split:split*2]
    train_sampler = Subset(dataset, train_indices)
    valid_sampler = Subset(dataset, val_indices)
    test_sampler = Subset(dataset, test_indices)
    train_loader = DataLoader(train_sampler, batch_size=128, num_workers=8)
    test_loader = DataLoader(valid_sampler, batch_size=128, shuffle=False, num_workers=8)

    model = ResNetWithMeta(num_meta_features=3, num_classes=len(dataset.classes)) 

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    loss_fn = nn.CrossEntropyLoss()

    for epoch in range(10):  # Number of epochs
        model.train()
        running_loss = 0
        corr = 0
        
        for images, meta_info, labels in tqdm(train_loader):
            images, meta_info, labels = images.to(device), meta_info.to(device), labels.to(device) 
            optimizer.zero_grad()
            outputs = model(images, meta_info)
            loss = loss_fn(outputs, labels)        
            loss.backward()        
            optimizer.step()        
            _, pred = outputs.max(dim=1)        
            corr += pred.eq(labels).sum().item()        
            running_loss += loss.item() * images.size(0)        

        acc = corr / len(train_loader.dataset)    
        print(f"Epoch {epoch+1}, Loss: {running_loss / len(train_loader.dataset)}, Accuracy: {acc}") 
